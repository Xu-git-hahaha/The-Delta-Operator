import torch
from torchvision import transforms
from datasets import load_dataset
from torch.utils.data import DataLoader
from tqdm import tqdm
import os


IMAGE_SIZE = 64
BATCH_SIZE = 1000  
SAVE_PATH = "data/celeba_64x64.pt"




def prepare_celeba():
    if os.path.exists(SAVE_PATH):
        print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨: {SAVE_PATH}ï¼Œç›´æ¥åŠ è½½ä½¿ç”¨å³å¯ã€‚")
        return

    print("ğŸš€ å¼€å§‹é€šè¿‡ Hugging Face ä¸‹è½½ CelebA (Aligned)...")
    
    
    try:
        dataset = load_dataset("nielsr/celeba-faces", split="train")
    except Exception as e:
        print(f"Hugging Face ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ (å¯èƒ½éœ€è¦æ¢¯å­): {e}")
        return

    print(f"ğŸ“¦ æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} å¼ å›¾ç‰‡")
    print(f"âš™ï¸ æ­£åœ¨é¢„å¤„ç†: Resize({IMAGE_SIZE}) -> ToTensor -> Normalize([-1, 1])...")

    
    transform = transforms.Compose([
        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        transforms.CenterCrop(IMAGE_SIZE),  
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  
    ])

    
    def process_batch(batch):
        
        pixel_values = [transform(img.convert("RGB")) for img in batch['image']]
        return torch.stack(pixel_values)

    
    all_tensors = []

    
    
    total = len(dataset)
    for i in tqdm(range(0, total, BATCH_SIZE)):
        end = min(i + BATCH_SIZE, total)
        batch_imgs = dataset[i:end]
        processed = process_batch(batch_imgs)
        all_tensors.append(processed)

    print("ğŸ’¾ æ­£åœ¨æ‹¼æ¥å¹¶ä¿å­˜ä¸º .pt æ–‡ä»¶ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    full_tensor = torch.cat(all_tensors, dim=0)

    os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)
    torch.save(full_tensor, SAVE_PATH)

    print(f"âœ… æˆåŠŸ! æ•°æ®å·²ä¿å­˜è‡³ {SAVE_PATH}")
    print(f"ğŸ“Š Tensor å½¢çŠ¶: {full_tensor.shape}")
    print(f"   (N, C, H, W) = ({full_tensor.shape[0]}, 3, 64, 64)")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(SAVE_PATH) / (1024 ** 3):.2f} GB")


if __name__ == "__main__":
    prepare_celeba()