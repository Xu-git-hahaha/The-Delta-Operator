import torch
from torchvision import transforms
from datasets import load_dataset
from tqdm import tqdm
import os


SAVE_PATH = "data/tiny_imagenet_64x64.pt"




def prepare_tiny_imagenet():
    if os.path.exists(SAVE_PATH):
        print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨: {SAVE_PATH}")
        return

    print("ğŸš€ å¼€å§‹é€šè¿‡ Hugging Face ä¸‹è½½ Tiny ImageNet...")
    
    try:
        dataset = load_dataset("zh-plus/tiny-imagenet", split="train")
    except Exception as e:
        print(f"ä¸‹è½½å¤±è´¥: {e}")
        return

    print(f"ğŸ“¦ æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} å¼ å›¾ç‰‡")
    print(f"âš™ï¸ æ­£åœ¨é¢„å¤„ç†: ToTensor -> Normalize([-1, 1])...")

    
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    all_tensors = []
    labels = []

    
    batch_size = 1000
    for i in tqdm(range(0, len(dataset), batch_size)):
        batch = dataset[i: i + batch_size]
        imgs = batch['image']
        lbls = batch['label']  

        processed_imgs = []
        for img in imgs:
            
            if img.mode != 'RGB':
                img = img.convert('RGB')
            processed_imgs.append(transform(img))

        all_tensors.append(torch.stack(processed_imgs))
        labels.append(torch.tensor(lbls))

    print("ğŸ’¾ æ­£åœ¨æ‹¼æ¥å¹¶ä¿å­˜...")
    full_tensor = torch.cat(all_tensors, dim=0)
    full_labels = torch.cat(labels, dim=0)

    
    data_dict = {
        "images": full_tensor,
        "labels": full_labels
    }

    os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)
    torch.save(data_dict, SAVE_PATH)

    print(f"âœ… æˆåŠŸ! æ•°æ®å·²ä¿å­˜è‡³ {SAVE_PATH}")
    print(f"ğŸ“Š å›¾ç‰‡å½¢çŠ¶: {full_tensor.shape}, æ ‡ç­¾å½¢çŠ¶: {full_labels.shape}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(SAVE_PATH) / (1024 ** 3):.2f} GB")


if __name__ == "__main__":
    prepare_tiny_imagenet()